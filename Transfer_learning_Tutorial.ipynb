{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer_learning Tutorial",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMc5AhV7DSPrf6BKD48biNK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wonjae124/2021_Lab_project/blob/main/Transfer_learning_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "ALg-t-y28L-3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'{device} is available')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOrQlQZQ7yPa",
        "outputId": "4bfdcdf1-6267-4661-8a34-d0fc7733f0cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0 is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 사전 학습 모델 불러와서 GPU에 올리기"
      ],
      "metadata": {
        "id": "KAMyh33x9LGd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA5LYkC65qIc",
        "outputId": "337ebd39-db5f-48d8-bc27-a0cf158b5ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/inception.py:83: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/googlenet.py:80: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import torchvision.models as models\n",
        "alexnet = models.alexnet().to(device)\n",
        "resnet18 = models.resnet18().to(device)\n",
        "vgg16 = models.vgg16().to(device)\n",
        "densenet = models.densenet161().to(device) \n",
        "inception = models.inception_v3().to(device)\n",
        "googlenet = models.googlenet().to(device)\n",
        "shufflenet = models.shufflenet_v2_x1_0().to(device)\n",
        "mobilenet_v2 = models.mobilenet_v2().to(device)\n",
        "wide_resnet50_2 = models.wide_resnet50_2().to(device)\n",
        "mnasnet = models.mnasnet1_0().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR10을 위한 ResNet18을 불러오기"
      ],
      "metadata": {
        "id": "xiORczxQ9c4a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = torchvision.models.resnet18(pretrained=True).to(device)\n",
        "summary(model1,(3,7,7))\n",
        "\n",
        "#ResNet, VGG16, VGG19는 224 by 224 사이즈의 이미지이므로 커널 사이즈가 7 by 7이고 맥스풀링은 사용한다.\n",
        "#보통, CIFAR10은 이미지가 28 by 28 이므로 크기가 작아서 커널 사이즈를 3 by 3, 맥스풀링 없이 모델 구조 만든다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06y4cul89kpl",
        "outputId": "62599742-de5e-498c-c351-f0968b16faca"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1             [-1, 64, 4, 4]           9,408\n",
            "       BatchNorm2d-2             [-1, 64, 4, 4]             128\n",
            "              ReLU-3             [-1, 64, 4, 4]               0\n",
            "         MaxPool2d-4             [-1, 64, 2, 2]               0\n",
            "            Conv2d-5             [-1, 64, 2, 2]          36,864\n",
            "       BatchNorm2d-6             [-1, 64, 2, 2]             128\n",
            "              ReLU-7             [-1, 64, 2, 2]               0\n",
            "            Conv2d-8             [-1, 64, 2, 2]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 2, 2]             128\n",
            "             ReLU-10             [-1, 64, 2, 2]               0\n",
            "       BasicBlock-11             [-1, 64, 2, 2]               0\n",
            "           Conv2d-12             [-1, 64, 2, 2]          36,864\n",
            "      BatchNorm2d-13             [-1, 64, 2, 2]             128\n",
            "             ReLU-14             [-1, 64, 2, 2]               0\n",
            "           Conv2d-15             [-1, 64, 2, 2]          36,864\n",
            "      BatchNorm2d-16             [-1, 64, 2, 2]             128\n",
            "             ReLU-17             [-1, 64, 2, 2]               0\n",
            "       BasicBlock-18             [-1, 64, 2, 2]               0\n",
            "           Conv2d-19            [-1, 128, 1, 1]          73,728\n",
            "      BatchNorm2d-20            [-1, 128, 1, 1]             256\n",
            "             ReLU-21            [-1, 128, 1, 1]               0\n",
            "           Conv2d-22            [-1, 128, 1, 1]         147,456\n",
            "      BatchNorm2d-23            [-1, 128, 1, 1]             256\n",
            "           Conv2d-24            [-1, 128, 1, 1]           8,192\n",
            "      BatchNorm2d-25            [-1, 128, 1, 1]             256\n",
            "             ReLU-26            [-1, 128, 1, 1]               0\n",
            "       BasicBlock-27            [-1, 128, 1, 1]               0\n",
            "           Conv2d-28            [-1, 128, 1, 1]         147,456\n",
            "      BatchNorm2d-29            [-1, 128, 1, 1]             256\n",
            "             ReLU-30            [-1, 128, 1, 1]               0\n",
            "           Conv2d-31            [-1, 128, 1, 1]         147,456\n",
            "      BatchNorm2d-32            [-1, 128, 1, 1]             256\n",
            "             ReLU-33            [-1, 128, 1, 1]               0\n",
            "       BasicBlock-34            [-1, 128, 1, 1]               0\n",
            "           Conv2d-35            [-1, 256, 1, 1]         294,912\n",
            "      BatchNorm2d-36            [-1, 256, 1, 1]             512\n",
            "             ReLU-37            [-1, 256, 1, 1]               0\n",
            "           Conv2d-38            [-1, 256, 1, 1]         589,824\n",
            "      BatchNorm2d-39            [-1, 256, 1, 1]             512\n",
            "           Conv2d-40            [-1, 256, 1, 1]          32,768\n",
            "      BatchNorm2d-41            [-1, 256, 1, 1]             512\n",
            "             ReLU-42            [-1, 256, 1, 1]               0\n",
            "       BasicBlock-43            [-1, 256, 1, 1]               0\n",
            "           Conv2d-44            [-1, 256, 1, 1]         589,824\n",
            "      BatchNorm2d-45            [-1, 256, 1, 1]             512\n",
            "             ReLU-46            [-1, 256, 1, 1]               0\n",
            "           Conv2d-47            [-1, 256, 1, 1]         589,824\n",
            "      BatchNorm2d-48            [-1, 256, 1, 1]             512\n",
            "             ReLU-49            [-1, 256, 1, 1]               0\n",
            "       BasicBlock-50            [-1, 256, 1, 1]               0\n",
            "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-53            [-1, 512, 1, 1]               0\n",
            "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
            "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-58            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
            "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-62            [-1, 512, 1, 1]               0\n",
            "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-65            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                 [-1, 1000]         513,000\n",
            "================================================================\n",
            "Total params: 11,689,512\n",
            "Trainable params: 11,689,512\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.17\n",
            "Params size (MB): 44.59\n",
            "Estimated Total Size (MB): 44.77\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for j, (name,param) in enumerate(model1.named_parameters()): # 레이어의 이름 확인하기. \n",
        "    print(j, name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNStA_XXwZF9",
        "outputId": "1fc143c3-0de8-4dc4-8875-4d9bd87dce1a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 conv1.weight\n",
            "1 bn1.weight\n",
            "2 bn1.bias\n",
            "3 layer1.0.conv1.weight\n",
            "4 layer1.0.bn1.weight\n",
            "5 layer1.0.bn1.bias\n",
            "6 layer1.0.conv2.weight\n",
            "7 layer1.0.bn2.weight\n",
            "8 layer1.0.bn2.bias\n",
            "9 layer1.1.conv1.weight\n",
            "10 layer1.1.bn1.weight\n",
            "11 layer1.1.bn1.bias\n",
            "12 layer1.1.conv2.weight\n",
            "13 layer1.1.bn2.weight\n",
            "14 layer1.1.bn2.bias\n",
            "15 layer2.0.conv1.weight\n",
            "16 layer2.0.bn1.weight\n",
            "17 layer2.0.bn1.bias\n",
            "18 layer2.0.conv2.weight\n",
            "19 layer2.0.bn2.weight\n",
            "20 layer2.0.bn2.bias\n",
            "21 layer2.0.downsample.0.weight\n",
            "22 layer2.0.downsample.1.weight\n",
            "23 layer2.0.downsample.1.bias\n",
            "24 layer2.1.conv1.weight\n",
            "25 layer2.1.bn1.weight\n",
            "26 layer2.1.bn1.bias\n",
            "27 layer2.1.conv2.weight\n",
            "28 layer2.1.bn2.weight\n",
            "29 layer2.1.bn2.bias\n",
            "30 layer3.0.conv1.weight\n",
            "31 layer3.0.bn1.weight\n",
            "32 layer3.0.bn1.bias\n",
            "33 layer3.0.conv2.weight\n",
            "34 layer3.0.bn2.weight\n",
            "35 layer3.0.bn2.bias\n",
            "36 layer3.0.downsample.0.weight\n",
            "37 layer3.0.downsample.1.weight\n",
            "38 layer3.0.downsample.1.bias\n",
            "39 layer3.1.conv1.weight\n",
            "40 layer3.1.bn1.weight\n",
            "41 layer3.1.bn1.bias\n",
            "42 layer3.1.conv2.weight\n",
            "43 layer3.1.bn2.weight\n",
            "44 layer3.1.bn2.bias\n",
            "45 layer4.0.conv1.weight\n",
            "46 layer4.0.bn1.weight\n",
            "47 layer4.0.bn1.bias\n",
            "48 layer4.0.conv2.weight\n",
            "49 layer4.0.bn2.weight\n",
            "50 layer4.0.bn2.bias\n",
            "51 layer4.0.downsample.0.weight\n",
            "52 layer4.0.downsample.1.weight\n",
            "53 layer4.0.downsample.1.bias\n",
            "54 layer4.1.conv1.weight\n",
            "55 layer4.1.bn1.weight\n",
            "56 layer4.1.bn1.bias\n",
            "57 layer4.1.conv2.weight\n",
            "58 layer4.1.bn2.weight\n",
            "59 layer4.1.bn2.bias\n",
            "60 fc.weight\n",
            "61 fc.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fc.in_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sceshfNsHhpR",
        "outputId": "d7269802-8cfe-4448-997c-ae52a9c32a6c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "model2.conv1 = nn.Conv2d(3,64, kernel_size = 3, stride = 1, padding = 1)\n",
        "\n",
        "num_ftrs = model2.fc.in_features # 512 \n",
        "\n",
        "model2.fc = nn.Linear(num_ftrs,10) # 512 -> 10으로 바꾸자\n",
        "\n",
        "model2 = model2.to(device)"
      ],
      "metadata": {
        "id": "mPH9QKBu7bKy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fc.in_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLlKJxxoHCiH",
        "outputId": "2680ccbe-71a3-4d47-eb5a-dcf89865ddfc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model2,(3,7,7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2RnlpDRBkQZ",
        "outputId": "d21efe7a-b306-4596-b343-ed6521b61629"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1             [-1, 64, 7, 7]           1,792\n",
            "       BatchNorm2d-2             [-1, 64, 7, 7]             128\n",
            "              ReLU-3             [-1, 64, 7, 7]               0\n",
            "         MaxPool2d-4             [-1, 64, 4, 4]               0\n",
            "            Conv2d-5             [-1, 64, 4, 4]          36,864\n",
            "       BatchNorm2d-6             [-1, 64, 4, 4]             128\n",
            "              ReLU-7             [-1, 64, 4, 4]               0\n",
            "            Conv2d-8             [-1, 64, 4, 4]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 4, 4]             128\n",
            "             ReLU-10             [-1, 64, 4, 4]               0\n",
            "       BasicBlock-11             [-1, 64, 4, 4]               0\n",
            "           Conv2d-12             [-1, 64, 4, 4]          36,864\n",
            "      BatchNorm2d-13             [-1, 64, 4, 4]             128\n",
            "             ReLU-14             [-1, 64, 4, 4]               0\n",
            "           Conv2d-15             [-1, 64, 4, 4]          36,864\n",
            "      BatchNorm2d-16             [-1, 64, 4, 4]             128\n",
            "             ReLU-17             [-1, 64, 4, 4]               0\n",
            "       BasicBlock-18             [-1, 64, 4, 4]               0\n",
            "           Conv2d-19            [-1, 128, 2, 2]          73,728\n",
            "      BatchNorm2d-20            [-1, 128, 2, 2]             256\n",
            "             ReLU-21            [-1, 128, 2, 2]               0\n",
            "           Conv2d-22            [-1, 128, 2, 2]         147,456\n",
            "      BatchNorm2d-23            [-1, 128, 2, 2]             256\n",
            "           Conv2d-24            [-1, 128, 2, 2]           8,192\n",
            "      BatchNorm2d-25            [-1, 128, 2, 2]             256\n",
            "             ReLU-26            [-1, 128, 2, 2]               0\n",
            "       BasicBlock-27            [-1, 128, 2, 2]               0\n",
            "           Conv2d-28            [-1, 128, 2, 2]         147,456\n",
            "      BatchNorm2d-29            [-1, 128, 2, 2]             256\n",
            "             ReLU-30            [-1, 128, 2, 2]               0\n",
            "           Conv2d-31            [-1, 128, 2, 2]         147,456\n",
            "      BatchNorm2d-32            [-1, 128, 2, 2]             256\n",
            "             ReLU-33            [-1, 128, 2, 2]               0\n",
            "       BasicBlock-34            [-1, 128, 2, 2]               0\n",
            "           Conv2d-35            [-1, 256, 1, 1]         294,912\n",
            "      BatchNorm2d-36            [-1, 256, 1, 1]             512\n",
            "             ReLU-37            [-1, 256, 1, 1]               0\n",
            "           Conv2d-38            [-1, 256, 1, 1]         589,824\n",
            "      BatchNorm2d-39            [-1, 256, 1, 1]             512\n",
            "           Conv2d-40            [-1, 256, 1, 1]          32,768\n",
            "      BatchNorm2d-41            [-1, 256, 1, 1]             512\n",
            "             ReLU-42            [-1, 256, 1, 1]               0\n",
            "       BasicBlock-43            [-1, 256, 1, 1]               0\n",
            "           Conv2d-44            [-1, 256, 1, 1]         589,824\n",
            "      BatchNorm2d-45            [-1, 256, 1, 1]             512\n",
            "             ReLU-46            [-1, 256, 1, 1]               0\n",
            "           Conv2d-47            [-1, 256, 1, 1]         589,824\n",
            "      BatchNorm2d-48            [-1, 256, 1, 1]             512\n",
            "             ReLU-49            [-1, 256, 1, 1]               0\n",
            "       BasicBlock-50            [-1, 256, 1, 1]               0\n",
            "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-53            [-1, 512, 1, 1]               0\n",
            "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
            "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-58            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
            "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-62            [-1, 512, 1, 1]               0\n",
            "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-65            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,174,026\n",
            "Trainable params: 11,174,026\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.35\n",
            "Params size (MB): 42.63\n",
            "Estimated Total Size (MB): 42.98\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Freezing"
      ],
      "metadata": {
        "id": "E7f-8_Ect-rV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = torchvision.models.alexnet(pretrained=True)\n",
        "print(f\"origin {model4.classifier[6]}\")\n",
        "\n",
        "num_ftrs = model4.classifier[6].in_features\n",
        "model4.classifier[6] = nn.Linear(num_ftrs, 10) #피처 추출 부분은 프리징 시키고 분류 파트(출력 레이어의 노드)를 클래수 수와 맞춰 준다.\n",
        "\n",
        "print(f\"After {model4.classifier[6]}\")\n",
        "\n",
        "model4 = model4.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNdDoBkGt7aP",
        "outputId": "3fe22251-0031-4b43-f80a-dbefd50c4a8a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "origin Linear(in_features=4096, out_features=1000, bias=True)\n",
            "After Linear(in_features=4096, out_features=10, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,(name,param) in enumerate(model4.named_parameters()): #모델 파라미터명 확인\n",
        "    print(i, name)\n",
        "#피처 추출 부분은 프리징 시키고 분류 파트(출력 레이어의 노드)를 클래수 수와 맞춰 준다.\n",
        "#0~9번은 feature 추출 부분\n",
        "# 10 ~ 15 부분은 분류 부분"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_O6IKk3uV3M",
        "outputId": "9334bfb9-6599-4ef3-853a-e63e10f8d2bb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 features.0.weight\n",
            "1 features.0.bias\n",
            "2 features.3.weight\n",
            "3 features.3.bias\n",
            "4 features.6.weight\n",
            "5 features.6.bias\n",
            "6 features.8.weight\n",
            "7 features.8.bias\n",
            "8 features.10.weight\n",
            "9 features.10.bias\n",
            "10 classifier.1.weight\n",
            "11 classifier.1.bias\n",
            "12 classifier.4.weight\n",
            "13 classifier.4.bias\n",
            "14 classifier.6.weight\n",
            "15 classifier.6.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GrNy9dAnxS-1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 피쳐 부분 프리징"
      ],
      "metadata": {
        "id": "mAxk5rtYu8ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i,(name,param) in enumerate(model4.named_parameters()):\n",
        "    print(i, name, param.requires_grad) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyEBqerdyo_C",
        "outputId": "d5f8c066-ad9b-4ec1-8994-d031ace39928"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 features.0.weight True\n",
            "1 features.0.bias True\n",
            "2 features.3.weight True\n",
            "3 features.3.bias True\n",
            "4 features.6.weight True\n",
            "5 features.6.bias True\n",
            "6 features.8.weight True\n",
            "7 features.8.bias True\n",
            "8 features.10.weight True\n",
            "9 features.10.bias True\n",
            "10 classifier.1.weight True\n",
            "11 classifier.1.bias True\n",
            "12 classifier.4.weight True\n",
            "13 classifier.4.bias True\n",
            "14 classifier.6.weight True\n",
            "15 classifier.6.bias True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,(name,param) in enumerate(model4.named_parameters()):\n",
        "    param.requires_grad = False \n",
        "    if i == 9:      #0~9까지 False로 프리징 시켰다.\n",
        "        print('end')\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cipjHGruMkr",
        "outputId": "8b1d1ee7-3f82-484d-d217-c0d3b65aa41c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requires_grad = False 확인하기"
      ],
      "metadata": {
        "id": "Lrn02Dzove_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f_list = [0, 3, 6, 8, 10] \n",
        "c_list = [1, 4, 6]\n",
        "for i in f_list:\n",
        "    print(model4.features[i].weight.requires_grad)\n",
        "    print(model4.features[i].bias.requires_grad)\n",
        "for j in c_list:\n",
        "    print(model4.classifier[j].weight.requires_grad)\n",
        "    print(model4.classifier[j].bias.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnKayNiLvNt-",
        "outputId": "1d2b01a6-3688-48c6-ce69-7cb605f0dd2e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    }
  ]
}