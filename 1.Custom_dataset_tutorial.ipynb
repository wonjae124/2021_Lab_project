{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Custom_dataset_tutorial",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "16ivnpvcg--q0pgLd1QIb2YhxaJda3wtp",
      "authorship_tag": "ABX9TyOhIyheOw0XWQJbMXxVGcVv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wonjae124/2021_Lab_project/blob/main/1.Custom_dataset_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#출처 : https://github.com/developer0hye/Custom-CNN-based-Image-Classification-in-PyTorch/blob/master/main.py \n",
        "import os \n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torchvision import transforms\n"
      ],
      "metadata": {
        "id": "joultphuGk7p"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "  def read_data_set(self):\n",
        "\n",
        "    all_img_files = []\n",
        "    all_labels = []\n",
        "\n",
        "    class_names = os.walk(self.data_set_path).__next__()[1]\n",
        "\n",
        "    for index, class_name in enumerate(class_names):\n",
        "      label = index\n",
        "      img_dir = os.path.join(self.data_set_path, class_name)\n",
        "      img_files = os.walk(img_dir).__next__()[2]\n",
        "\n",
        "      for img_file in img_files:\n",
        "        img_file = os.path.join(img_dir, img_file)\n",
        "        img = Image.open(img_file)\n",
        "        if img is not None:\n",
        "          all_img_files.append(img_file)\n",
        "          all_labels.append(label)\n",
        "\n",
        "    return all_img_files, all_labels, len(all_img_files), len(class_names)\n",
        "\n",
        "  def __init__(self, data_set_path, transforms=None):\n",
        "    self.data_set_path = data_set_path\n",
        "    self.image_files_path, self.labels, self.length, self.num_classes = self.read_data_set()\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = Image.open(self.image_files_path[index])\n",
        "    image = image.convert(\"RGB\") #convert가 내장함수인가?\n",
        "\n",
        "    if self.transforms is not None:\n",
        "       image = self.transforms(image)\n",
        "    return {'image':image, 'label':self.labels[index]}\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.length"
      ],
      "metadata": {
        "id": "ZfqquBXaGzyE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomConvNet(nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "    super(CustomConvNet, self).__init__()\n",
        "\n",
        "    self.layer1 = self.conv_module(3, 16)\n",
        "    self.layer2 = self.conv_module(16, 32)\n",
        "    self.layer3 = self.conv_module(32, 64)\n",
        "    self.layer4 = self.conv_module(64, 128)\n",
        "    self.layer5 = self.conv_module(128, 256)\n",
        "    self.gap = self.global_avg_pool(256, num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = self.layer4(out)\n",
        "    out = self.layer5(out)\n",
        "    out = self.gap(out)\n",
        "    out = out.view(-1, num_classes)\n",
        "\n",
        "    return out\n",
        "\n",
        "  def conv_module(self, in_num, out_num):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_num,out_num,kernel_size=3, stride =1, padding =1),\n",
        "        nn.BatchNorm2d(out_num),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "    \n",
        "  def global_avg_pool(self, in_num, out_num):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_num,out_num,kernel_size=3, stride=1,padding=1),\n",
        "        nn.BatchNorm2d(out_num),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.AdaptiveAvgPool2d((1,1)))\n",
        "    "
      ],
      "metadata": {
        "id": "Y7SRB_GgU_By"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyper_param_epoch = 20\n",
        "hyper_param_batch = 8\n",
        "hyper_param_learning_rate = 0.001\n",
        "\n",
        "transforms_train = transforms.Compose([transforms.Resize((128,128)),\n",
        "                                       transforms.RandomRotation(10.),\n",
        "                                       transforms.ToTensor()])\n",
        "\n",
        "transforms_test = transforms.Compose([transforms.Resize((128,128)),\n",
        "                                      transforms.ToTensor()])\n",
        "\n",
        "train_data_set = CustomImageDataset(data_set_path=\"/content/drive/MyDrive/Colab Notebooks/train\", transforms=transforms_train)\n",
        "train_loader = DataLoader(train_data_set, batch_size=hyper_param_batch, shuffle=True)\n",
        "\n",
        "test_data_set = CustomImageDataset(data_set_path=\"/content/drive/MyDrive/Colab Notebooks/test\", transforms=transforms_test)\n",
        "test_loader = DataLoader(test_data_set, batch_size = hyper_param_batch, shuffle=True)\n",
        "\n",
        "if not(train_data_set.num_classes == test_data_set.num_classes):\n",
        "   print(\"error:Numbers of class in training set and test set are not equal\")\n",
        "   exit()\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n"
      ],
      "metadata": {
        "id": "5S_RsmqIWhB3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data_set))\n",
        "print(len(test_data_set))\n",
        "\n",
        "print(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-comjw-7ij11",
        "outputId": "c10f6a66-9c3f-4fbb-9334-008d18b67f72"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "20\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7f1c0a511c10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = train_data_set.num_classes\n",
        "custom_model = CustomConvNet(num_classes=num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(custom_model.parameters(), lr = hyper_param_learning_rate)\n"
      ],
      "metadata": {
        "id": "mrLAP5f7erqs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for e in range(hyper_param_epoch):\n",
        "    for i_batch, item in enumerate(train_loader):\n",
        "      images = item['image'].to(device)\n",
        "      labels = item['label'].to(device)\n",
        "\n",
        "      outputs = custom_model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if (i_batch+1)%hyper_param_batch == 0:\n",
        "        print('Epoch [{}/{}],Loss: {:.4f}'\n",
        "              .format(e+1, hyper_param_epoch,loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EWFt4nsoM6q",
        "outputId": "64e0147c-fdc3-4bb2-d686-6ac5c31fddaa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20],Loss: 0.4673\n",
            "Epoch [2/20],Loss: 0.2165\n",
            "Epoch [3/20],Loss: 0.2710\n",
            "Epoch [4/20],Loss: 0.2022\n",
            "Epoch [5/20],Loss: 0.2068\n",
            "Epoch [6/20],Loss: 0.1971\n",
            "Epoch [7/20],Loss: 0.1931\n",
            "Epoch [8/20],Loss: 0.3453\n",
            "Epoch [9/20],Loss: 0.2115\n",
            "Epoch [10/20],Loss: 0.2035\n",
            "Epoch [11/20],Loss: 0.2012\n",
            "Epoch [12/20],Loss: 0.1942\n",
            "Epoch [13/20],Loss: 0.1915\n",
            "Epoch [14/20],Loss: 0.1871\n",
            "Epoch [15/20],Loss: 0.1853\n",
            "Epoch [16/20],Loss: 0.7566\n",
            "Epoch [17/20],Loss: 0.2015\n",
            "Epoch [18/20],Loss: 0.1861\n",
            "Epoch [19/20],Loss: 0.3363\n",
            "Epoch [20/20],Loss: 0.1593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for item in test_loader:\n",
        "        images = item['image'].to(device)\n",
        "        labels = item['label'].to(device)\n",
        "        outputs = custom_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += len(labels)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "    print('Test Accuracy of the model on the {} test images: {} %'.format(total, 100 * correct / total))"
      ],
      "metadata": {
        "id": "DIZVvL0vYBEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ace83374-03de-430e-a03c-00007da8cfd9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([False, False, False, False, False, False, False, False])\n",
            "tensor([False, False, False, False, False, False, False, False])\n",
            "tensor([False, False, False, False])\n",
            "Test Accuracy of the model on the 20 test images: 0.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VKrat2cPU_HJ"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}