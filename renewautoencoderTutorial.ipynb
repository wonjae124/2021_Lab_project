{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "renewautoencoderTutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMVHi9KluGMxluZWiwB29q8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wonjae124/2021_Lab_project/blob/main/renewautoencoderTutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uelA5VyciwSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import skimage.util.noise as noise #Denoise 패키지인 Sckit.image의 util모듈. return 값은 numpy로 다루는 ndarray임. https://scikit-image.org/docs/stable/api/skimage.util.html#random-noise \n",
        "\n",
        "transform=transforms.ToTensor()\n",
        "train_set = datasets.MNIST(root='./data',train=True,download=True,transform=transform)\n",
        "test_set = datasets.MNIST(root='./data',train=False,download=True,transform=transform)\n",
        "num_workers=0 #?\n",
        "batch_size = 50\n",
        "\n",
        "train_set_arr=train_set.data.numpy() #numpy 자료형(ndarray) 변환.\n",
        "test_set_arr=test_set.data.numpy()\n",
        "\n",
        "Snp_train_set_arr1 = noise.random_noise(train_set_arr,mode='s&p',amount=0.1) #함수 random_noise를 사용한다. speckle도 추가 가능\n",
        "Snp_train_set_arr2 = noise.random_noise(train_set_arr,mode='s&p',amount=0.3)\n",
        "Snp_train_set_arr3 = noise.random_noise(train_set_arr,mode='s&p',amount=0.5)\n",
        "\n",
        "Snp_test_set_arr1 = noise.random_noise(test_set_arr,mode='s&p',amount=0.1) \n",
        "Snp_test_set_arr2 = noise.random_noise(test_set_arr,mode='s&p',amount=0.3)\n",
        "Snp_test_set_arr3 = noise.random_noise(test_set_arr,mode='s&p',amount=0.5)\n",
        "\n",
        "Gn_train_set_arr1 = noise.random_noise(train_set_arr,mode='gaussian',mean=0.1) #gaussian,speckle noise의 비율을 결정하는 파라미터인 mean이다. default는 0이다.\n",
        "Gn_train_set_arr2 = noise.random_noise(train_set_arr,mode='gaussian',mean=0.3)\n",
        "Gn_train_set_arr3 = noise.random_noise(train_set_arr,mode='gaussian',mean=0.5)\n",
        "\n",
        "Gn_test_set_arr1 = noise.random_noise(test_set_arr,mode='gaussian',mean=0.1) \n",
        "Gn_test_set_arr2 = noise.random_noise(test_set_arr,mode='gaussian',mean=0.3)\n",
        "Gn_test_set_arr3 = noise.random_noise(test_set_arr,mode='gaussian',mean=0.5)\n",
        "\n",
        "\n",
        "titles = ['Snp_week', 'Snp_moderate', 'Snp_strong', 'Gaussian_week', \n",
        "          'Gaussian_moderate', 'Gaussian_strong']\n",
        "images = [ Snp_train_set_arr1[0], Snp_train_set_arr2[0], Snp_train_set_arr3[0],\n",
        "          Gn_train_set_arr1[0], Gn_train_set_arr2[0], Gn_train_set_arr3[0]]\n",
        "\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1), plt.imshow(images[i],cmap='gray')\n",
        "  plt.title(titles[i])\n",
        "  plt.xticks([]), plt.yticks([]) #xticks?\n",
        "\n",
        "#torch.from_numpy(img).float().div(255.0).unsqueeze(0)로 해결 하였습니다. 감사 합니다.\n",
        "\n",
        "Snp_week_train = torch.from_numpy(Snp_train_set_arr1).float().div(255.0).unsqueeze(0)\n",
        "Snp_moderate_train = torch.from_numpy(Snp_train_set_arr2)\n",
        "Snp_strong_train= torch.from_numpy(Snp_train_set_arr3)\n",
        "\n",
        "Gaussian_week_train = torch.from_numpy(Gn_train_set_arr1)\n",
        "Gaussian_moderate_train = torch.from_numpy(Gn_train_set_arr2)\n",
        "Gaussian_strong_train = torch.from_numpy(Gn_train_set_arr3)\n",
        "\n",
        "Snp_week_test = torch.from_numpy(Snp_test_set_arr1)\n",
        "Snp_moderate_test = torch.from_numpy(Snp_test_set_arr2)\n",
        "Snp_strong_test = torch.from_numpy(Snp_test_set_arr3)\n",
        "\n",
        "Gaussian_week_test = torch.from_numpy(Gn_test_set_arr1)\n",
        "Gaussian_moderate_test = torch.from_numpy(Gn_test_set_arr2)\n",
        "Gaussian_strong_test = torch.from_numpy(Gn_test_set_arr3)\n"
      ],
      "metadata": {
        "id": "BrswLYbDH5YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_set_arr.shape)\n",
        "print(test_set_arr.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqEKDBCdM4fB",
        "outputId": "9700a66f-109a-4d29-d27c-752a5d948771"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Snp_week_train_loader = DataLoader(Snp_week_train,batch_size=batch_size,num_workers=num_workers)\n",
        "Snp_week_test_loader = DataLoader(Snp_week_test,batch_size=batch_size,num_workers=num_workers)\n",
        "\n",
        "Snp_moderate_train_loader = DataLoader(Snp_moderate_train,batch_size=batch_size,num_workers=num_workers)\n",
        "Snp_moderate_test_loader = DataLoader(Snp_moderate_test,batch_size=batch_size,num_workers=num_workers)\n",
        "\n",
        "Snp_strong_train_loader = DataLoader(Snp_strong_train,batch_size=batch_size,num_workers=num_workers)\n",
        "Snp_strong_test_loader = DataLoader(Snp_strong_test,batch_size=batch_size,num_workers=num_workers)"
      ],
      "metadata": {
        "id": "lf7W8K01LSMt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Snp_week_train_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWrwKUKBUbfd",
        "outputId": "ce6274b9-7def-40ae-d996-a3c2426acaf4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f354f6b0210>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3, 1, 20, 128)\n",
        "x1 = np.squeeze(x)\n",
        "print(x.shape)\n",
        "print(x1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgQV5XQIHBVb",
        "outputId": "30028f6e-66ab-41b9-ea07-a5248dc73d0c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1, 20, 128])\n",
            "torch.Size([3, 20, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN_Denoise를 정의하기\n",
        "#Conv2D(input_channel,Output_channel,filter_size,stride는 이동 간격(기본1), padding=1(image주변을 padding으로 둘러싸서 이미지 크기 키움. 사용안하는 0이 default임)\n",
        "#Max_pooling으로 이미지의 대표 feature(최대,최소,평균)를 추출\n",
        "class ConvDenoiser(nn.Module):\n",
        "  def __init__(self):\n",
        "\n",
        "    #Encoder layer\n",
        "    super(ConvDenoiser, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1,32,3, padding=1) #depth를 1에서 32로 변환, 필터 크기는 3X3. zero 패딩 사용하므로 이미지 크기는 8X8로 유지 된다.\n",
        "    self.conv2 = nn.Conv2d(32,16,3, padding=1)  #depth를 32에서 16으로 줄이고 필터 크기는 3X3\n",
        "    self.conv3 = nn.Conv2d(16,8,3, padding =1) #depth를 16에서 8로, 필터 크기는 3X3\n",
        "    self.pool = nn.MaxPool2d(2,2) #필터 크기 2X2로 해서 이미지의 feature 추출함.\n",
        "\n",
        "    #Decoder layer\n",
        "    self.t_conv1 = nn.ConvTranspose2d(8,8,3,stride=2) #stride로 필터의 간격을 2로 늘려서 차원을 늘린다. 패딩 사용 하지 않으므로 7X7로 사이즈 줄어듦\n",
        "    self.t_conv2 = nn.ConvTranspose2d(8,16,2,stride=2) #transpose layer가 뭐하는거지? conv2D와 동일한 개수를 써야 되나?\n",
        "    self.t_conv3= nn.ConvTranspose2d(16,32,2,stride=2) #필터의 간격을 2로 늘리는 이유?\n",
        "    self.conv_out = nn.Conv2d(32,1,3,padding=1) #depth32->1로 만든다. 패딩 사용해서 마지막은 8X8 사이즈로 만들어준다.\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    ##encode##\n",
        "    ##활성화 함수 relu를 사용해서 hidden_layer를 쌓는다. \n",
        "    x = F.relu(self.conv1(x)) #1단 히든레이어\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(self.conv2(x)) #2단 히든레이어\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(self.conv3(x)) #3단 히든레이어\n",
        "    x = self.pool(x)\n",
        "    #Compressed representaion이다.\n",
        "    ##Decode##\n",
        "    ##마찬가지로 hidden_layer를 만든다.\n",
        "    x = F.relu(self.t_conv1(x)) #1단 히든레이어 \n",
        "    x = F.relu(self.t_conv2(x)) \n",
        "    x = F.relu(self.t_conv3(x))\n",
        "    x = F.sigmoid(self.conv_out(x)) #마지막에 sigmoid 쓰는 이유->마지막 출력 레이어는 0~1.0사이의 값을 사용함. \n",
        "    return x\n"
      ],
      "metadata": {
        "id": "U3Nz4o_6sgBS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학습 할 모델 설정\n",
        "model = ConvDenoiser()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiML-yHfMnDf",
        "outputId": "30ffd6c5-ce85-4a32-e6df-47ee705ea41f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvDenoiser(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (t_conv1): ConvTranspose2d(8, 8, kernel_size=(3, 3), stride=(2, 2))\n",
            "  (t_conv2): ConvTranspose2d(8, 16, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (t_conv3): ConvTranspose2d(16, 32, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (conv_out): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model loss_function\n",
        "#optimizer는 error(또는 loss)를 줄이는데 사용함. weight+=weight-n*dE/dw로 gradient 미세조정한다. n은 학습율,E는 에러율이다.E(w)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #Gradient와 learning rate를 둘 다 고려해서 방향을 찾는 Adam optimizer를 사용한다.\n",
        "n_epochs = 5\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "  #loss mornitor\n",
        "  train_loss = 0.0\n",
        "#model training\n",
        "  for data in Snp_week_train_loader:\n",
        "       \n",
        "       optimizer.zero_grad() #모든 최적화 된 변수(optimizer?)의 gradient를 clear한다. \n",
        "\n",
        "    #foward pass임. 노이즈 입력에 의한 모델 예측값을 출력한다.\n",
        "\n",
        "       outputs = model(data)\n",
        "    #caculate the loss\n",
        "    #target은 원본이미지이다.\n",
        "       loss = criterion(outputs,data) #MSELoss(input, target)로 오차를 구해낸다.\n",
        "       loss.backward()  #자동 미분 진행한다.\n",
        "       optimizer.step() #파라미터 업데이트함(최적화 한 걸음 실행하겠다) \n",
        "       train_loss += loss.item()*data.size(0) #images.size(0)가 뭔데?\n",
        "\n",
        "   #평균적인 학습 통계를 출력하기\n",
        "       train_loss = train_loss/len(Snp_week_train_loader)\n",
        "       print('Epoch:{} \\t Training Loss: {:.6f}'.format(epoch,train_loss)) #중괄호 사이로 format(문자열포멧팅함수)에서 지정한 값이 들어간다\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "VNOu0m8sMnAR",
        "outputId": "8c05a249-4c58-4f62-8c3c-af3d097353b7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-07f44e34205c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#foward pass임. 노이즈 입력에 의한 모델 예측값을 출력한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m        \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;31m#caculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#target은 원본이미지이다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-49db48a47989>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m##encode##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m##활성화 함수 relu를 사용해서 hidden_layer를 쌓는다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#1단 히든레이어\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#2단 히든레이어\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [32, 1, 3, 3], but got 3-dimensional input of size [50, 28, 28] instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#<torch.utils.data.dataloader.DataLoader object at 0x7f4121698e10>"
      ],
      "metadata": {
        "id": "H0VETLVqMnFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Snp_train_set_arr1.shape)\n",
        "print(Snp_test_set_arr1.shape)"
      ],
      "metadata": {
        "id": "NpfcCOfxMnHx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5035ec2-ee05-433f-9190-7af535187789"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Snp_week_train_loader\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8xCrnKMXTl6",
        "outputId": "343ee3e8-dd1b-4a17-cc40-a1c5fed26d67"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f354f6b0210>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IGinUF3IZLfx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}